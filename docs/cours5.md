# Cours: Streaming

# 1. Messaging Systems üìå
Les syst√®mes modernes g√©n√®rent et traitent des flux continus de donn√©es : transactions bancaires, activit√©s sur les r√©seaux sociaux, capteurs IoT, ou encore logs d'applications. Pour g√©rer efficacement ces flux en temps r√©el, les syst√®mes de messagerie (messaging systems) jouent un r√¥le crucial.

### 1.1) Qu'est-ce qu'un syst√®me de messaging ?

Un syst√®me de messaging (_Messaging System_) permet l'√©change de donn√©es entre applications via un m√©canisme de communication asynchrone. 
Dans cette architecture:
- une application appel√©e "**producer**" g√©n√®re et envoie des messages, qui sont ensuite achemin√©s
- via un "**broker**" (le gestionnaire central de messages) 
- vers une application "**consumer**" qui les consomme. Ex: une application Spark Streaming, un site web, un outil d'analyse etc... 
  
Le broker agit comme un interm√©diaire fiable, stockant temporairement les messages dans des files d'attente (_queues_) avant leur livraison. 

Cette approche d√©coupl√©e (via l‚Äôinterm√©diation du broker) permet aux applications de se concentrer uniquement sur le traitement des donn√©es, sans avoir √† g√©rer les complexit√©s de la ***communication*** directe entre elles. 
En effet le producer et le consumer peuvent ainsi fonctionner de mani√®re ind√©pendante, √† leur propre rythme, gr√¢ce √† la nature asynchrone du syst√®me. De plus, fini le risque de perte de donn√©e si le r√©cepteur (l'application qui re√ßoit les donn√©es) n'est pas disponible. 

![alt text](img/cours5/msg_broker.png)

>Attention: S'il est vrai que tout syst√®me de messaging s'appuie sur un message broker, tout message broker n'est pas syst√®me de messaging! 
>Ex de message broker: RabbitMQ, Apache ActiveMQ
>Ex de syst√®me de messaging: Apache  Kafka

### 1.2) Patrons de messageries: 
Les patrons de messageries d√©finissent diff√©rentes fa√ßons d'acheminer les messages entre les applications. Ils r√©pondent √† des besoins diff√©rents selon que l'on souhaite une communication directe entre deux points ou une diffusion plus large de l'information.

#### 1.2.1) Syst√®mes de messagerie Point √† Point (Fan-out)
Dans ce mod√®le, un message est envoy√© par un producer √† une file d'attente sp√©cifique et ne peut √™tre consomm√© que par un seul consumer. C'est comme un courrier postal : une fois qu'une lettre est r√©cup√©r√©e par un destinataire, elle n'est plus disponible pour les autres. Ce patron est id√©al pour des cas d'usage comme la r√©partition des t√¢ches entre workers (traitement de commandes, calculs distribu√©s) o√π chaque message ne doit √™tre trait√© qu'une seule fois.

![alt text](img/cours5/point-to-point.gif)

#### 1.2.2) Syst√®mes de messagerie Publish/Subscribe
Dans ce mod√®le (souvent appel√© "pub/sub"), un producer publie des messages sur un "topic" (canal th√©matique) et tous les consumers abonn√©s √† ce topic re√ßoivent une copie du message. C'est comparable √† un r√©seau social o√π un post est visible par tous les followers. Ce patron est parfait pour la diffusion d'√©v√©nements (mises √† jour de prix, notifications, alertes) o√π plusieurs applications ont besoin de r√©agir √† la m√™me information.

![alt text](img/cours5/pub-sub.gif)



# 2. Kafka

### 2.1) Introduction üìå
Apache Kafka est une **plateforme de streaming distribu√©e** qui permet de :
- Publier et consommer des flux de donn√©es (comparable √† un ***syst√®me de messaging***)
- Stocker ces donn√©es de mani√®re **durable et r√©siliente**
- Traiter les donn√©es en **temps r√©el** d√®s leur arriv√©e

Notions cl√©s: 
- **Topic**: un topic Kafka peut √™tre vu comme une cat√©gorie ou un canal de donn√©es, qui est divis√© en une ou plusieurs partitions. C'est l'unit√© logique de base.
- **Partition**: s√©quence ordonn√©e et immuable de messages. Chaque broker peut avoir z√©ro ou plusieurs partitions par topic
- **R√©pliques (Replicas)**:  backups¬†d'une partition. Elles ne sont jamais lues ni modifi√©es par les acteurs externes, elles servent uniquement √† pr√©venir la perte de donn√©es.
- **Leader**: N≈ìud unique responsable de g√©rer les lectures/√©critures d'une partition. Kafka essaie automatiquement de distribuer les leaders de mani√®re √©quitable entre les brokers pour √©viter la surcharge d'un seul n≈ìud.
- **Follower**: N≈ìuds qui r√©pliquent les donn√©es du leader. Peuvent √™tre promus leader si le leader actuel devient indisponible 

>Ex: Nous pouvons cr√©er un topic 'sales' et partitionner les messages par r√©gion g√©ographique 


![alt text](img/cours5/archi_kafka.jpg)

Dans l'exemple ci-dessus, un topic est configur√© en trois partitions. On a 2 producers, 3 consumers et 3 brokers et un facteur de r√©plication = 3 (car 3 r√©pliques identiques de chaque partition Pi). Avec le noeud 1 qui est leader pour la Partition1.

NB: Quand un message est envoy√© √† un topic, il est en r√©alit√© stock√© dans une de ses partitions
- Le choix de la partition peut √™tre :
    - Al√©atoire
    - D√©termin√© par une cl√© de partitionnement
    - Sp√©cifi√© explicitement

Avantages du partitionnement :
- Parall√©lisme : plusieurs consommateurs peuvent lire diff√©rentes partitions simultan√©ment
- Scalabilit√© : les donn√©es sont distribu√©es sur plusieurs brokers
- Haute disponibilit√© : les partitions peuvent √™tre r√©pliqu√©es


![alt text](img/cours5/image-1.png)


Enfin, il est important de mentionner que Apache Kafka n'est pas dot√© d'une interface utilisateur int√©gr√©e. Cependant, il existe plusieurs outils tiers qui fournissent une interface utilisateur graphique (GUI) pour g√©rer, surveiller et interagir avec les clusters Kafka. Ces outils sont tr√®s populaires car ils simplifient le processus de visualisation des flux de donn√©es (data stream), la gestion des sujets, la surveillance des consommateurs et des producteurs, et m√™me la r√©solution des probl√®mes. L'un des plus populaire est Conduktor.

![alt text](img/cours5/conduktor.png)

### 2.2) Kafka & Zookeeper

Un cluster Kafka est compos√© de plusieurs brokers qui se r√©partissent la charge de travail. Ces brokers, bien que capables de g√©rer des centaines de milliers d'op√©rations par seconde et de stocker des t√©raoctets de donn√©es, sont stateless - ils ne maintiennent pas leur propre √©tat.

C'est l√† qu'intervient ZooKeeper, un service centralis√© qui assure la coordination du cluster. Il g√®re les configurations, maintient l'√©tat des brokers et notifie les producteurs et consommateurs de tout changement dans le cluster (comme l'ajout d'un nouveau broker ou une panne).

![alt text](img/cours5/zookeeper-kafka.png)

>Nb: Kafka √©voluant, les nouvelles versions abandonnent progressivement ZooKeeper au profit de KRaft (Kafka Raft), un protocole de consensus int√©gr√© qui permet une gestion autonome des m√©tadonn√©es du cluster.



# 3. Stream data processing 

### 3.1) Introduction üìå

Le traitement de flux (stream processing) repr√©sente une approche moderne du traitement de donn√©es. Il permet d'analyser et traiter les donn√©es en **temps r√©el**, d√®s leur cr√©ation ou r√©ception, contrairement au traitement par lots (batch processing) qui op√®re sur des ensembles de donn√©es √† intervalles r√©guliers.

Cette m√©thode est particuli√®rement pr√©cieuse lorsque la rapidit√© d'acc√®s aux donn√©es est critique pour l'entreprise. Par exemple, pour la d√©tection de fraudes bancaires, le monitoring d'√©quipements industriels ou l'analyse de comportements clients en temps r√©el.

Il constitue la couche "Speed Layer" dans l'architecture Lambda, et surtout est au c≈ìur de l'architecture Kappa.

![alt text](img/cours4/kappa_archi.PNG)


Alors que les message brokers (via Apache Kafka) assurent le transport fiable et le stockage temporaire des flux de donn√©es, des outils de traitement de flux comme Apache Spark streaming et Apache Flink se chargent d'analyser et de transformer ces flux de donn√©es en temps r√©el. 

![alt text](img/cours5/spark_flink_kafka.PNG)



### 3.2) comparaison Flink, Storm, Spark Streaming

Les 3 outils de traitement de flux √† savoir sont: Flink, Storm et Spark Streaming. 
Voyons comment ils se distinguent et dans quel cas en privil√©giez un plut√¥t qu'un autre. 

| Aspect                     | Apache Spark Streaming                                                   | Apache Flink                                                                                                       | Apache Storm                                          |
| -------------------------- | ------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------- |
| **Description**            | Framework de traitement unifi√© (batch + streaming)                       | Moteur de traitement distribu√© orient√© streaming natif                                                             | Framework de streaming open source                    |
| **Mod√®le de traitement**   | Micro-batch (par intervalles)                                            | Streaming natif (continu)                                                                                          | Streaming natif (continu)                             |
| **Latence**                | Quelques secondes                                                        | Quelques millisecondes                                                                                             | Quelques millisecondes                                |
| **Fen√™trage**              | Fen√™tres temporelles et glissantes<br>                                   | Tr√®s flexible avec fen√™tres personnalisables<br>*(fen√™tres bas√©es sur le temps, les √©v√©nements ou personnalis√©es)* | Fen√™tres basiques<br>*(fen√™tres temporelles simples)* |
| **√âtat applicatif**        | Stockage bas√© sur RDD en m√©moire                                         | √âtat g√©r√© nativement avec checkpoints                                                                              | Sans √©tat par d√©faut, stockage externe n√©cessaire     |
| **Force principale**       | Polyvalence et √©cosyst√®me riche                                          | Performance pure streaming                                                                                         | Simplicit√© et faible latence                          |
| **Machine Learning**       | MLlib int√©gr√©, √©cosyst√®me mature                                         | FlinkML basique                                                                                                    | Limit√©, int√©gration externe n√©cessaire                |
| **Use cases**              | ‚Ä¢ Analytique temps r√©el<br>‚Ä¢ ML √† grande √©chelle<br>‚Ä¢ Traitement hybride | ‚Ä¢ Streaming pur<br>‚Ä¢ Complex Event Processing<br>‚Ä¢ Analyse temps r√©el                                              | ‚Ä¢ Flux simples<br>‚Ä¢ Cas d'usage temps r√©el basiques   |
| **Maturit√©/Support**       | Tr√®s mature, large communaut√©                                            | Mature, communaut√© croissante                                                                                      | Mature mais moins actif                               |
| **Facilit√© d'utilisation** | Moyenne √† Simple                                                         | Complexe au d√©but                                                                                                  | Simple                                                |
Retenez que: 
- Storm est historiquement le premier mais est moins utilis√© dans les nouveaux projets
- Spark est souvent choisi pour sa polyvalence
- Flink est le choix privil√©gi√© pour du streaming pur avec des besoins complexes



### 3.3) Spark Streaming 

Apache Spark Streaming est un composant (API) de l'√©cosyst√®me Apache Spark qui permet le traitement de donn√©es en temps r√©el. Cette extension du framework Spark permet aux d√©veloppeurs de profiter des m√™mes APIs (Spark Core, Spark SQL (DataFrame, DataSets), MLlib par exemple) que le traitement batch pour cr√©er des applications de streaming, facilitant ainsi le d√©veloppement d'applications temps r√©el √† grande √©chelle.

#### 3.3.1) Architecture et Fonctionnement de Base üìå
Le principe fondamental de Spark Streaming repose sur sa capacit√© √† traiter les donn√©es en continu. Diff√©rents modes de traitement sont possibles. Ceux-ci d√©finissent **comment** les donn√©es sont trait√©es. 

- Mode Batch: Bien que non consid√©r√© comme du "vrai" streaming, ce mode permet de traiter des donn√©es historiques en utilisant les m√™mes APIs que le streaming. C'est particuli√®rement utile pour tester ou retraiter des donn√©es historiques.
  
- **Mode Micro-batch**: C'est l'approche par d√©faut de Spark Structured Streaming (appelation de la nouvelle API Spark pour le streaming). 
  Elle consiste √† regrouper les donn√©es entrantes en petits lots trait√©s √† intervalles r√©guliers. Cette approche offre un bon compromis entre latence et d√©bit, avec une garantie de traitement "exactly-once" (un enregistrement ne sera trait√© qu'une seule fois!), essentielle pour de nombreuses applications m√©tier.
  
- **Mode Continu**: Introduit de mani√®re exp√©rimentale dans Spark 2.3, ce mode vise √† r√©duire la latence en traitant chaque enregistrement d√®s son arriv√©e. Il offre une garantie "at-least-once", signifiant qu'un enregistrement sera trait√© au moins une fois, parfois plus.

#### 3.3.2) Interaction avec les Sources de Donn√©es üìå
Spark Streaming propose plusieurs modes de lecture, particuli√®rement utiles lors de l'interaction avec des syst√®mes comme Apache Kafka :
- Le mode **Assign** permet un contr√¥le pr√©cis en sp√©cifiant exactement quelles partitions lire
- Le mode **Subscribe** offre une approche plus flexible en s'abonnant √† des topics sp√©cifiques
- Le mode **SubscribePattern** permet une lecture en s'abonnant √† des topics correspondant √† un pattern sp√©cifique
  
  Logique de lecture des stream de donn√©es: 
![alt text](img/cours5/read_stream_data.png)

#### 3.3.3) Mode de d√©clenchement üìå
Le traitement des donn√©es est contr√¥l√© par diff√©rents modes de d√©clenchement (Trigger Modes). Ceux-ci d√©finissent **quand** le traitement est d√©clench√©. 

- Mode par **d√©faut**: Lance le traitement d√®s que le batch (lot) pr√©c√©dent est termin√©
- Le mode **micro-lots √† intervalles fixes**: Traite les donn√©es √† intervalles de temps fixes (ex: toutes les 5 minutes). Les donn√©es s'accumulant entre les intervalles.
- Le mode **one-time**:  Traite toutes les donn√©es disponibles, puis s'arr√™te. (Utile pour des traitements ponctuels ou tests)
- Le mode **continu**: Sp√©cifique au mode de traitement continu. Il v√©rifie constamment l'arriv√©e de nouvelles donn√©es √† traiter

Ex de d√©clenchement √† intervalle fixe = toutes les 1 seconde:
![alt text](img/cours5/mode_declenchement_exemple.png)

#### 3.3.4) Modes pour l'√©criture en sortie üìå
Spark Streaming dispose de trois modes pour √©crire les r√©sultats :

- Le mode **Complete** √©crit l'int√©gralit√© des r√©sultats √† chaque fois, id√©al pour des agr√©gations compl√®tes.
  
- Le mode **Append**: Seules les nouvelles lignes ajout√©es au tableau de r√©sultats depuis le dernier d√©clenchement sont √©crites dans le stockage externe. Id√©al lorsqu'il n'est pas pr√©vu que les lignes existantes du tableau de r√©sultats soient modifi√©es.
   
- Le mode **Update**: Seules les lignes qui ont √©t√© mises √† jour dans la table de r√©sultats depuis le dernier d√©clenchement sont √©crites dans le stockage externe. Et si ce sont de nouvelles elles sont append. 


##### 3.3.5 Fonctionnalit√©s avanc√©es de Spark Streaming

- **Les Types d'Op√©rations de Traitement**

	Dans Spark Streaming, nous distinguons deux grandes familles d'op√©rations qui r√©pondent √† des besoins diff√©rents : les op√©rations sans √©tat et les op√©rations avec √©tat.

	-Les Op√©rations **Sans √âtat (Stateless)**: üìå
	Ces op√©rations sont les plus simples √† appr√©hender car elles traitent chaque enregistrement de mani√®re isol√©e, sans tenir compte du contexte ou des donn√©es pr√©c√©dentes. Imaginez un filtre qui ne laisse passer que les transactions sup√©rieures √† 1000‚Ç¨, ou une transformation qui convertit chaque temp√©rature de Celsius en Fahrenheit. Ces op√©rations (filter, map, flatMap, select, where) sont simples, rapides et faciles √† parall√©liser car elles ne n√©cessitent pas de maintenir un contexte entre les traitements.
	
	-Les Op√©rations **Avec √âtat (Stateful)** üìå
	√Ä l'inverse, les op√©rations avec √©tat maintiennent un contexte au fil du temps. Elles sont plus complexes mais aussi plus puissantes. Prenez l'exemple d'un compteur de visites par utilisateur : il doit se souvenir des visites pr√©c√©dentes pour incr√©menter le compteur correctement. Ces op√©rations (agr√©gations, compteurs cumulatifs, moyennes mobiles, d√©duplication de donn√©es) n√©cessitent une gestion particuli√®re de la m√©moire et des m√©canismes de checkpoint pour garantir la fiabilit√© du traitement.
	Ex: 
	![alt text](img/cours5/groupby_stateful.PNG)


- **Les Jointures**

	Spark Streaming propose deux types de jointures qui enrichissent consid√©rablement les possibilit√©s de traitement.

	-Les Jointures **Stream-to-Stream**: permettent de combiner deux flux de donn√©es en temps r√©el. Imaginez un syst√®me qui doit associer des paiements avec des commandes en temps r√©el : les deux flux doivent √™tre synchronis√©s et joints correctement. C'est une op√©ration complexe qui n√©cessite de maintenir un √©tat pour les donn√©es qui n'ont pas encore trouv√© leur correspondance.
	
	-Les Jointures **Stream-to-Static**: sont plus simples car elles associent un flux avec des donn√©es statiques. Par exemple, enrichir un flux de transactions avec les informations clients stock√©es dans une base de donn√©es. Ces jointures sont g√©n√©ralement plus performantes car un c√¥t√© de la jointure reste constant.

- **La Gestion du Temps et des Retards**

	La gestion du temps est cruciale dans le traitement en temps r√©el, et Spark Streaming propose des m√©canismes sophistiqu√©s pour la g√©rer.
	
	-**Le Watermarking**: c'est un concept fondamental r√©pondant √† une question critique: combien de temps devons-nous attendre les donn√©es retardataires ? 
	Il agit comme un garde-fou qui permet de :
	- G√©rer proprement les donn√©es qui arrivent en retard
	- Lib√©rer la m√©moire des anciennes fen√™tres devenues obsol√®tes
	- Maintenir la coh√©rence des r√©sultats malgr√© les al√©as du temps r√©el
	
	-**Le Fen√™trage Temporel (Windowing)**: compl√®te le watermarking en permettant d'analyser les donn√©es par tranches de temps. Que ce soit avec des fen√™tres fixes (tumbling), glissantes (sliding) ou bas√©es sur l'activit√© (session), ce m√©canisme permet des analyses temporelles pr√©cises et pertinentes.
		![alt text](img/cours5/windowing.png)
	
	Prenons un exemple concret : imaginons un syst√®me de monitoring IoT qui re√ßoit des donn√©es de milliers de capteurs. Avec une fen√™tre glissante de 5 minutes (pour appliquer notre agr√©gation) et un watermark de 10 minutes.
	Nous pouvons ainsi calculer des moyennes mobiles tout en g√©rant les capteurs qui envoient leurs donn√©es en retard :
	
	```python
	streamingDF
	  .withWatermark("timestamp", "10 minutes")
	  .groupBy(
	    window("timestamp", "5 minutes"),
	    "deviceId"
	  )
	  .agg(avg("temperature"))
	```






---

Sources:
- https://dataengineering.wiki/Concepts/Stream+Data+Processing
- https://insatunisia.github.io/TP-BigData/tp3/
- https://eda-visuals.boyney.io/visuals/message-queue-vs-event-broker
- https://blog.bytebytego.com/