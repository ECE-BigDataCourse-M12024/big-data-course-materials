# Cours : SGBD et structure de donnÃ©es pour le Big Data

# 1. Introduction ğŸ“Œ

### DÃ©finitions:

- **Base de donnÃ©es (BDD)** : Collection organisÃ©e de donnÃ©es structurÃ©es.
  >Imaginez-la comme une bibliothÃ¨que numÃ©rique oÃ¹ chaque livre (donnÃ©e) est classÃ© selon un systÃ¨me prÃ©cis pour faciliter sa recherche et son utilisation
  
- **SystÃ¨me de Gestion de Base de DonnÃ©es (SGBD)** : Logiciel permettant de gÃ©rer, interroger et maintenir les bases de donnÃ©es.
  Exemples de SGBD: MySQL, PostgreSQL, Oracle, Microsoft SQL Server ...
  >C'est comme le bibliothÃ©caire de notre bibliothÃ¨que numÃ©rique. Il organise les donnÃ©es, gÃ¨re les accÃ¨s, assure la cohÃ©rence et la sÃ©curitÃ© des informations.
  
### Types de bases de donnÃ©es
- **BDD Relationnelles**: organisÃ©es en tables avec des relations entre elles, elles utilisent gÃ©nÃ©ralement le langage SQL, et sont conÃ§ues pour **respecter les propriÃ©tÃ©s ACID** (AtomicitÃ©, Consistence, Isolation, DurabilitÃ©), offrant une structure rigide adaptÃ©e aux donnÃ©es structurÃ©es.
- **BDD Non-relationnelles**: appelÃ©es NoSQL, elles proposent **divers modÃ¨les de donnÃ©es** flexibles (clÃ©-valeur, document, colonne, graphe) adaptÃ©s aux donnÃ©es **non structurÃ©es ou semi-structurÃ©es**, sacrifiant parfois certaines garanties ACID au profit de la **scalabilitÃ© et de la flexibilitÃ©**.


# 2. Rappels

### OLAP vs OLTP 

Le traitement analytique en ligne (OLAP) et le traitement transactionnel en ligne (OLTP) sontÂ **deux systÃ¨mes de traitement de donnÃ©es diffÃ©rents conÃ§us Ã  des fins diffÃ©rentes**Â . 

- (un systÃ¨me) OLTP (Online Transaction Processing) est optimisÃ© pour le traitement transactionnel et les mises Ã  jour en temps rÃ©el. Ce type de systÃ¨me de traitement est au cÅ“ur des transactions numÃ©riques quotidiennes, alimentant des systÃ¨mes tels que les distributeurs automatiques de billets, les services bancaires en ligne, les caisses enregistreuses ou encore les plateformes de commerce Ã©lectronique. Il reprÃ©sente la **base de donnÃ©es opÃ©rationnelle** ou la base de donnÃ©es d'une application, en utilisant un **modÃ¨le relationnel** (des objets appelÃ©s "entitÃ©s" qui sont reliÃ©s entre eux), souvent avec une structure normalisÃ©e Ã©vitant la redondance et assurant la consistance des donnÃ©es.
  
  Ex: illustration d'un modÃ¨le de donnÃ©e relationnel
>![alt text](img/cours3/modele_relationnel.PNG)


- Les systÃ¨mes OLAP (Online Analytical Processing) permettent l'analyse complexe de grandes quantitÃ©s de donnÃ©es en utilisant une modÃ©lisation multidimensionnelle pour l'analyse, oÃ¹ les donnÃ©es sont organisÃ©es en cubes OLAP composÃ©s de **faits** (mesures numÃ©riques) et de **dimensions** (contextes d'analyse), souvent avec une structure dÃ©normalisÃ©e pour optimiser les performances des requÃªtes analytiques.

![alt text](img/cours3/olap.png)

Comparaison:

![alt text](img/cours3/olap_vs_oltp.PNG)

Les systÃ¨mes de stockages de donnÃ©es tel que: 'data warehouse' et 'datamart' sont de type OLAP, tandis que les 'database' sont de type OLTP. 

> Leur rappeller que dans le cadre de leur projet de groupe, il n'est pas nÃ©cessaire pour la visualization de s'appuyer sur un datawarehouse, une bdd ou mÃªme un fichier csv/excel/json suffit. 


# 3. Architecture et performance 

### 3.1) Cache, Memory, Disk

##### 3.1.1) Cache: Â 
C'est le **type de stockage de donnÃ©es le plus rapide et le plus petit**. Il est utilisÃ© pour stocker les donnÃ©es qui sont en cours de traitement ou qui sont en file dâ€™attente pour Ãªtre traitÃ©es. Il peut aussi Ãªtre utilisÃ© afin de conserver temporairement des donnÃ©es **frÃ©quemment consultÃ©es**, rÃ©duisant ainsi les temps d'accÃ¨s et amÃ©liorant les performances.
Les caches existent Ã  plusieurs niveaux: 
- CPU cache 
- RAM cache
- Disk cache
Ils servent Ã  rechercher rapidement des donnÃ©es au lieu d'accÃ©der Ã  des supports de stockage plus lents tels que la mÃ©moire vive ou les disques.
GÃ©nÃ©ralement lorsqu'on parle de cache on se rÃ©fÃ¨re au CPU cache (en fonction du contexte).

##### 3.1.2) MÃ©moire vive (RAM): 
**Type de mÃ©moire volatile** utilisÃ© par les ordinateurs pour stocker les donnÃ©es et les instructions en cours d'utilisation ou de traitement. 
Elle permet un accÃ¨s rapide Ã  la lecture et Ã  l'Ã©criture, ce qui permet Ã  l'unitÃ© centrale (CPU) de rÃ©cupÃ©rer rapidement les informations. 
A noter que les donnÃ©es contenues dans la RAM sont perdues lorsque l'ordinateur est mis hors tension.

##### 3.1.3) Disque dur (SSD, HDD):
**support de stockage non volatil** utilisÃ© pour stocker les donnÃ©es, les fichiers et les applications sur un ordinateur. Ils offrent une plus grande capacitÃ© de stockage que la RAM et conservent les donnÃ©es mÃªme lorsque l'ordinateur est Ã©teint, ce qui les rend adaptÃ©s au stockage de donnÃ©es Ã  long terme.


>Nb: Il existe aussi un autre type d'espace mÃ©moire appelÃ© 'ROM' (Read Only Memory). 
>Il est principalement utilisÃ©e pour stocker les microprogrammes dont le systÃ¨me a besoin pour dÃ©marrer et fonctionner (ex: BIOS/UFI).

Tableau de comparaison: 

| Feature                 | **CPU Cache**                             | **Memory (RAM)**                                        | **Disk Storage**                                             |
| ----------------------- | ----------------------------------------- | ------------------------------------------------------- | ------------------------------------------------------------ |
| **Purpose**                 | Speeds up CPU data access                 | Temporary storage for active data and programs          | Permanent storage for data and files                         |
| **Location**        | Inside the CPU (L1, L2, L3 caches)        | Separate from the CPU, on the motherboard               | On hard drives (HDD) or solid-state drives (SSD)             |
| **Speed**             | Extremely fast (nanoseconds)              | Fast (microseconds)                                     | Slow (milliseconds to seconds)                               |
| **Size**              | Small (typically a few MBs)               | Moderate (a few GBs to hundreds of GBs)                 | Large (hundreds of GBs to several TBs)                       |
| **Volatility**          | Volatile (data lost when power is off)    | Volatile (data lost when power is off)                  | Non-volatile (data retained when power is off)               |
| **Cost**                | Most expensive per GB                     | Moderate cost per GB                                    | Least expensive per GB                                       |
| **Accessibility**       | Frequently accessed data and instructions | Active data for running applications                    | Infrequently accessed data, files, and backups               |
| **Data Management** | Managed by the CPU                        | Managed by the OS and applications                      | Managed by the OS and file systems                           |
| **Hierarchy**          | Has multiple levels (L1, L2, L3)          | No hierarchy, but may have different types (DDR4, DDR5) | Usually one level, but can have different formats (HDD, SSD) |
| **Usage context**    | Accessed during CPU processing cycles     | Used during program execution                           | Used for long-term data storage                              |

Chaque cÅ“ur de processeur possÃ¨de sa propre mÃ©moire cache (L1 et L2 pour Ãªtre prÃ©cis). Le cache L3 est partagÃ© entre les diffÃ©rents cÅ“urs CPU. 

![alt text](img/cours3/cpu-cache.png)

Par CPU:

![alt text](img/cours3/diagram-glossary-caching.svg)

### 3.2) Structure de donnÃ©es au coeur des BDDs ğŸ“Œ

Les index, les hachages et les arbres sont des structures de donnÃ©es utilisÃ©es dans les bases de donnÃ©es pour optimiser l'accÃ¨s et la rÃ©cupÃ©ration des donnÃ©es. 

##### 3.2.1) Indexes
Concept et structures de donnÃ©es permettant d'optimiser la recherche d'enregistrement dans une base de donnÃ©e. Un index peut Ãªtre crÃ©e via diverses structures de donnÃ©es, le plus souvent via des tables de hachages ou des B-Trees (cf ce qui suit). 

![alt text](img/cours3/indexes.PNG)

Il est gÃ©nÃ©ralement stockÃ© dans un format clÃ©-valeur oÃ¹ la clÃ© est le champ ou la colonne (triÃ©) et la valeur est le(s) pointeur(s).
Ex: John Smith -> 152; Lisa Smith -> 001

Pensez Ã  l'index d'un livre : au lieu de parcourir chaque page pour trouver une information, on consulte l'index pour aller directement Ã  la bonne page.
Il est donc plus facile de retrouver une information en parcourant l'index que la table. 

Utilisez des index sur :
1. Les colonnes frÃ©quemment utilisÃ©es dans les clauses WHERE
2. Les colonnes impliquÃ©es dans les jointures (clÃ©s Ã©trangÃ¨res)
3. Les colonnes souvent utilisÃ©es pour le tri (ORDER BY)
4. Les colonnes avec une grande cardinalitÃ© (nombreuses valeurs uniques)

Nb: Les index peuvent aussi Ãªtre crÃ©e Ã  partir de plusieurs colonnes, Ã  la crÃ©ation ou aprÃ¨s que la table soit crÃ©Ã©e. 

```sql
CREATE INDEX idx_first_name ON employees (first_name); --single column
CREATE INDEX idx_name ON employees (last_name, first_name); --multiple columns


-- Utilisation implicite de l'index dans une requÃªte 
SELECT * FROM employees WHERE first_name = 'Alice';
```

>Attention: le gain en lecture et pour certaines opÃ©rations a un coÃ»t. 
>- consommation accrue de stockage: il faut bien stocker la table d'index
>- durÃ©e lors des opÃ©rations d'Ã©criture (create or update): car il faut aussi  mettre Ã  jour la table d'index
>- complexitÃ© de management: bien gÃ©rer le nombre d'index et s'assurer qu'ils rÃ©pondent bien aux besoins


##### 3.2.2) Hash 
Les fonctions de hachage font correspondre des donnÃ©es de taille arbitraire Ã  des valeurs de taille fixe. Les plus connus sont: SHA-256, SHA-251, BLAKE2.
Le hash sera le rÃ©sultat de l'application de la fonction de hachage sur une entrÃ©e. 
Cette entrÃ©e peut Ãªtre un du texte, une image, toute donnÃ©e. Elle manipule donc la reprÃ©sentation binaire de ces divers Ã©lÃ©ments. 

![alt text](img/cours3/hash.PNG)

En base de donnÃ©e, les tables de hachages sont gÃ©nÃ©ralement utilisÃ©es pour crÃ©er des indexes.
 
![alt text](img/cours3/hash_table.PNG)

Utilisez ce type d'index idÃ©alement pour:
- Pour des requÃªtes Ã  correspondance exacte
- Example: `SELECT * FROM users WHERE id = 1234`


##### 3.2.3) Arbres (Trees)

En informatique les arbres sont des type de donnÃ©es abstraites assez rÃ©pandues. Ils reprÃ©sentent la donnÃ©e sous une structure arborescente hiÃ©rarchique avec un ensemble de nÅ“uds connectÃ©s. Chaque nÅ“ud de l'arbre peut Ãªtre connectÃ© Ã  de nombreux enfants (en fonction du type d'arbre), mais doit Ãªtre connectÃ© Ã  un seul parent, Ã  l'exception du nÅ“ud racine ('root' node), qui n'a pas de parent.

En base de donnÃ©es, un type d'arbre est souvent utilisÃ©e pour **l'indexation des donnÃ©es**: B-tree.  Les arbres B sont des structures de donnÃ©es arborescentes auto-Ã©quilibrÃ©es (ie qui Ã©quilibre automatiquement la rÃ©partition des nÅ“uds, afin de conserver un Ã©quilibre Ã  chaque niveau de l'arbre) qui conservent des **donnÃ©es triÃ©es et permettent des opÃ©rations d'insertion, de suppression et de recherche efficaces**. 

Illustrations avec des nombres:
![alt text](img/cours3/graph_number.PNG)

Illustration avec des lettres:
![alt text](img/cours3/graph_letter.PNG)

Utilisez ce type d'index quand: 
- vous utilisez des requÃªtes de sÃ©lection de plage ou de tri
- Exemple: `SELECT * FROM users WHERE age BETWEEN 20 AND 30`

Dans le cas des indexes type B-Tree, l'Ã©criture est assez coÃ»teuse, en effet une insertion ou mise Ã  jour nÃ©cessite de recrÃ©er l'arbre afin de respecter son "Ã©quilibre". D'autres types d'arbres pour l'indexation existent, on citera notamment: B+ Tree, et LSM-Tree.

A noter que lorsque vous effectuer la commande: "CREATE INDEX" trÃ¨s souvent le type d'indexe crÃ©e est un B-Tree. Mais ce n'est pas tout le temps cas!
Certains SGBD comme PostgreSQL permettent d'avoir une approche hybride en offrant la possibilitÃ© de crÃ©er des index via fonctions de hachage et arbres (B-Trees). BÃ©nÃ©ficiant ainsi des avantages de chacune des approches, mais comme on l'a vu cela augmentera la complexitÃ© de la gestion des index mais aussi le coÃ»t des opÃ©rations d'Ã©critures. 


# 4. SystÃ¨mes de stockage de donnÃ©es ğŸ“Œ

### 4.1) DiffÃ©rents systÃ¨mes 
##### Database 
Une **base de donnÃ©es** est une **collection structurÃ©e** de donnÃ©es organisÃ©es en **tableaux**, **lignes** et **colonnes**. Elle est spÃ©cifiquement conÃ§ue pour **stocker** et **gÃ©rer** les donnÃ©es relatives Ã  des applications ou services.

##### Data Warehouse
Un **data warehouse** (entrepÃ´t de donnÃ©es) est un rÃ©fÃ©rentiel centralisÃ© conÃ§u pour **stocker**, **traiter** et **analyser** de grands volumes de **donnÃ©es structurÃ©es.** Il regroupe gÃ©nÃ©ralement des donnÃ©es provenant de sources multiples et prend en charge des requÃªtes et des analyses complexes.

![alt text](img/cours3/etl_data_warehouse.PNG)

##### Datamart
Un **data mart** est un **sous-ensemble** d'un **data warehouse**, souvent axÃ© sur un **secteur d'activitÃ© spÃ©cifique**, **dÃ©partement** ou **fonction**. Il est adaptÃ© aux besoins d'un groupe particulier d'utilisateurs au sein d'une organisation.

##### Datalake
Datalake ou lac de donnÃ©es en franÃ§ais, est un **rÃ©fÃ©rentiel centralisÃ©** qui stocke des donnÃ©es structurÃ©es et non structurÃ©es Ã  grande Ã©chelle, **dans leur format natif**.
Il englobe les donnÃ©es:
- structurÃ©es, 
- semi-structurÃ©es (JSON, XML) 
- et non structurÃ©es (texte, images, vidÃ©os).

CaractÃ©ristiques :
- Utilise la logique ELT (Extraction, Chargement, Transformation) plutÃ´t que ETL traditionnel. La transformation des donnÃ©es s'effectuant donc aprÃ¨s l'extraction et le dÃ©pÃ´t sur le data lake. 
- Supporte la virtualisation des donnÃ©es pour un accÃ¨s unifiÃ©.
  La virtualisation des donnÃ©es crÃ©e une couche d'abstraction au-dessus des diffÃ©rentes sources de donnÃ©es dans le lac. Cette couche permet d'accÃ©der Ã  toutes les donnÃ©es comme si elles Ã©taient dans une seule base de donnÃ©es unifiÃ©e, quel que soit leur format ou leur emplacement rÃ©el. (Ex: Apache Drill, Trino, Denodo, Hive...)
  
  >![alt text](img/cours3/apache_drill.PNG)

- IntÃ¨gre souvent un catalogue de donnÃ©es pour la gouvernance et la dÃ©couverte des donnÃ©es. 
- Utilise des formats de table spÃ©cifiques (comme Delta Lake) offrant des fonctionnalitÃ©s similaires aux bases de donnÃ©es sur des fichiers distribuÃ©s.
  
  ![alt text](img/cours3/common_data_lake_tech.PNG)


### 4.2) Comparaison

![alt text](img/cours3/diff_db_dm_dw_dl.PNG)



# 5. SystÃ¨me de fichiers (File systems) ğŸ“Œ

### Definition: 
Un **systÃ¨me de fichiers** est une mÃ©thode et une structure de donnÃ©es utilisÃ©es par les systÃ¨mes d'exploitation pour gÃ©rer et organiser les fichiers sur les pÃ©riphÃ©riques de stockage (tels que les disques durs, les disques SSD, les clÃ©s USB, etc.). Il dÃ©finit la maniÃ¨re dont les donnÃ©es sont stockÃ©es, rÃ©cupÃ©rÃ©es et organisÃ©es, ce qui permet aux utilisateurs et aux applications d'accÃ©der aux fichiers et de les manipuler efficacement. En principe, tout systÃ¨me de fichiers peut stocker n'importe quel format de fichier. Pour le systÃ¨me de fichiers, tous les fichiers ne sont que des sÃ©quences d'octets.

Il est composÃ© de :
- fichiers
- dossiers ou rÃ©pertoires
- mÃ©tadonnÃ©es de fichiers (type, date, taille, droits etc...)
- chemins d'accÃ¨s aux fichiers (filepath, ex: C://Users/Documents/MyFolder)

Exemple: Linux file systems
![alt text](img/cours3/linux_fs.jpg)
Il permet aux utilisateurs et aux applications de stocker, d'extraire et de gÃ©rer efficacement les fichiers. 

Dans le contexte du Big Data, les systÃ¨mes de fichiers traditionnels ne suffisent plus, car nous sommes dans un paradigme distribuÃ©. Plusieurs solutions ont Ã©tÃ© dÃ©veloppÃ©es pour rÃ©pondre aux besoins spÃ©cifiques du stockage et du traitement de grandes quantitÃ©s de donnÃ©es.

### Exemples de file systems:
- **HDFS (Hadoop Distributed File System)**:
	- Partie intÃ©grante de l'Ã©cosystÃ¨me Hadoop
	- CaractÃ©ristiques :
	    - DistribuÃ© : les donnÃ©es sont rÃ©parties sur plusieurs nÅ“uds
	    - Hautement tolÃ©rant aux pannes : rÃ©plication des donnÃ©es
	    - OptimisÃ© pour les grands fichiers et le streaming de donnÃ©es

- **DBFS (Databricks File System)**:
	- SystÃ¨me de fichiers **abstrait** utilisÃ© dans Databricks. Il permet d'accÃ©der Ã  diffÃ©rents types de fichiers (.png, .csv, .parquet, .orc etc...), situÃ©s Ã  divers endroits (espace de travail, cache, HDFS, BDD relationnelles/non-relationnelles). Il permet aussi d'implÃ©menter des politiques et controles d'accÃ¨s aux fichiers.
	- CaractÃ©ristiques :
	    - Compatible HDFS
	    - IntÃ©gration transparente avec le cloud (AWS S3, Azure Blob Storage, etc.)
	    - OptimisÃ© pour les workloads Spark
	- Concepts:
		- Mount: un objet qui sert de point d'accÃ¨s facile Ã  un systÃ¨me de stockage externe dans notre environnement Databricks. Lorsque vous crÃ©ez un montage (mount), vous dites Ã  Databricks : Â«Lorsque je fais rÃ©fÃ©rence Ã  ce chemin dans DBFS, je veux en fait accÃ©der Ã  cet emplacement de stockage externe spÃ©cifiqueÂ».
		- Root: le rÃ©pertoire "racine" permettant d'importer des fichiers ou crÃ©er des dossiers dans notre espace de travail
		- Ephemeral storage:  Le stockage Ã©phÃ©mÃ¨re est le stockage temporaire disponible sur les machines virtuelles au sein d'un cluster. Les donnÃ©es Ã©crites dessus (mis en cache) disparaisse une fois le cluster Ã©teint ou mis en arrÃªt.

- Cloud file systems:
	- ADLS (Azure Data Lake Systems Gen2): 
		```text
		abfs://mycontainer@mystorageaccount.dfs.core.windows.net/folder/file.csv
		```

	- Amazon S3
		```text
		s3a://my-bucket/folder/file.csv
		```

	- Google  Cloud storage
		```text
		gs://my-bucket/folder/file.csv
		```


# 6. Formats ğŸ“Œ
Les formats de fichiers dÃ©finissent la maniÃ¨re dont les donnÃ©es sont structurÃ©es dans un fichier (par exemple, CSV, Parquet, JSON). C'est Ã  l'application qui lit le fichier de comprendre et d'interprÃ©ter son format.

En big data les formats de fichiers jouent un rÃ´le crucial dans le stockage, le traitement et l'analyse des donnÃ©es. Des formats tels que Parquet, ORC et Avro sont conÃ§us pour traiter efficacement de grands volumes de donnÃ©es dans les environnements big data. Il est essentiel de comprendre ces formats pour optimiser les flux de donnÃ©es, garantir l'intÃ©gritÃ© des donnÃ©es et maximiser la vitesse de traitement.

![alt text](img/cours3/format_choix.PNG)


##### Comparaison des principaux formats: Avro, Orc et Parquet:

| Feature          | Avro                     | ORC                      | Parquet                 |
|------------------|--------------------------|--------------------------|-------------------------|
| Type             | Row-based                | Columnar                 | Columnar                |
| Compression      | Good                     | Excellent                | Excellent               |
| Read Performance | Good                     | Very High                | Very High               |
| Write Performance| Very Good                | Good                     | Moderate                |
| Schema Evolution | Excellent                | Good                     | Good                    |
| Splittable       | Yes                      | Yes                      | Yes                     |
| Language Support | Many languages           | Primarily Java           | Many languages          |
| Key Perk         | Flexible schema evolution| Fast for Hive queries    | Efficient for analytics |
| When to Use      | - Data serialization     | - Hive-based analytics   | - General analytics     |
|                  | - Frequent schema changes| - Fast HDFS integration  | - Data warehousing      |
|                  | - Write-heavy workloads  | - Read-heavy workloads   | - Read-heavy workloads  |
| Best For         | Streaming data, ETL      | Hive queries, HDFS       | General analytics       |
| Ecosystem Fit    | Kafka, Hadoop            | Hadoop, especially Hive  | Spark, general Big Data |

##### Quand choisir quel format ?
- **Avro**: si vous avez besoin d'une Ã©volution flexible des schÃ©mas ou si vous traitez des donnÃ©es en continu.
- **ORC**: si vous travaillez principalement avec Hive dans un environnement Hadoop.
- **Parquet**: pour l'analyse gÃ©nÃ©rale, en particulier si vous utilisez Spark ou si vous avez besoin d'un format qui fonctionne bien avec diffÃ©rents outils Big Data.


---
Sources:
- https://www.linkedin.com/pulse/differences-between-database-vs-data-warehouse-mart-lake-nguyen-tuan-ejo7c/
- https://www.ssp.sh/blog/data-warehouse-vs-data-lake-etl-vs-elt/
- https://www.ssp.sh/brain/data-lake-file-formats/
- https://blog.bytebytego.com/p/ep63-linux-file-system-explained