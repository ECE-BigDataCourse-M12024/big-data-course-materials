# Cours : SGBD et structure de donn√©es pour le Big Data

# 1. Introduction üìå

### D√©finitions:

- **Base de donn√©es (BDD)** : Collection organis√©e de donn√©es structur√©es.
  >Imaginez-la comme une biblioth√®que num√©rique o√π chaque livre (donn√©e) est class√© selon un syst√®me pr√©cis pour faciliter sa recherche et son utilisation
  
- **Syst√®me de Gestion de Base de Donn√©es (SGBD)** : Logiciel permettant de g√©rer, interroger et maintenir les bases de donn√©es.
  Exemples de SGBD: MySQL, PostgreSQL, Oracle, Microsoft SQL Server ...
  >C'est comme le biblioth√©caire de notre biblioth√®que num√©rique. Il organise les donn√©es, g√®re les acc√®s, assure la coh√©rence et la s√©curit√© des informations.
  
### Types de bases de donn√©es
- **BDD Relationnelles**: organis√©es en tables avec des relations entre elles, elles utilisent g√©n√©ralement le langage SQL, et sont con√ßues pour **respecter les propri√©t√©s ACID** (Atomicit√©, Consistence, Isolation, Durabilit√©), offrant une structure rigide adapt√©e aux donn√©es structur√©es.
- **BDD Non-relationnelles**: appel√©es NoSQL, elles proposent **divers mod√®les de donn√©es** flexibles (cl√©-valeur, document, colonne, graphe) adapt√©s aux donn√©es **non structur√©es ou semi-structur√©es**, sacrifiant parfois certaines garanties ACID au profit de la **scalabilit√© et de la flexibilit√©**.


# 2. Rappels

### OLAP vs OLTP 

Le traitement analytique en ligne (OLAP) et le traitement transactionnel en ligne (OLTP) sont¬†**deux syst√®mes de traitement de donn√©es diff√©rents con√ßus √† des fins diff√©rentes**¬†. 

- (un syst√®me) OLTP (Online Transaction Processing) est optimis√© pour le traitement transactionnel et les mises √† jour en temps r√©el. Ce type de syst√®me de traitement est au c≈ìur des transactions num√©riques quotidiennes, alimentant des syst√®mes tels que les distributeurs automatiques de billets, les services bancaires en ligne, les caisses enregistreuses ou encore les plateformes de commerce √©lectronique. Il repr√©sente la **base de donn√©es op√©rationnelle** ou la base de donn√©es d'une application, en utilisant un **mod√®le relationnel** (des objets appel√©s "entit√©s" qui sont reli√©s entre eux), souvent avec une structure normalis√©e √©vitant la redondance et assurant la consistance des donn√©es.
  
  Ex: illustration d'un mod√®le de donn√©e relationnel
>![alt text](img/cours3/modele_relationnel.PNG)


- Les syst√®mes OLAP (Online Analytical Processing) permettent l'analyse complexe de grandes quantit√©s de donn√©es en utilisant une mod√©lisation multidimensionnelle pour l'analyse, o√π les donn√©es sont organis√©es en cubes OLAP compos√©s de **faits** (mesures num√©riques) et de **dimensions** (contextes d'analyse), souvent avec une structure d√©normalis√©e pour optimiser les performances des requ√™tes analytiques.

![alt text](img/cours3/olap.png)

Comparaison:

![alt text](img/cours3/olap_vs_oltp.PNG)

Les syst√®mes de stockages de donn√©es tel que: 'data warehouse' et 'datamart' sont de type OLAP, tandis que les 'database' sont de type OLTP. 

> Leur rappeller que dans le cadre de leur projet de groupe, il n'est pas n√©cessaire pour la visualization de s'appuyer sur un datawarehouse, une bdd ou m√™me un fichier csv/excel/json suffit. 


# 3. Architecture et performance 

### 3.1) Cache, Memory, Disk

##### 3.1.1) Cache: ¬†
C'est le **type de stockage de donn√©es le plus rapide et le plus petit**. Il est utilis√© pour stocker les donn√©es qui sont en cours de traitement ou qui sont en file d‚Äôattente pour √™tre trait√©es. Il peut aussi √™tre utilis√© afin de conserver temporairement des donn√©es **fr√©quemment consult√©es**, r√©duisant ainsi les temps d'acc√®s et am√©liorant les performances.
Les caches existent √† plusieurs niveaux: 
- CPU cache 
- RAM cache
- Disk cache
Ils servent √† rechercher rapidement des donn√©es au lieu d'acc√©der √† des supports de stockage plus lents tels que la m√©moire vive ou les disques.
G√©n√©ralement lorsqu'on parle de cache on se r√©f√®re au CPU cache (en fonction du contexte).

##### 3.1.2) M√©moire vive (RAM): 
**Type de m√©moire volatile** utilis√© par les ordinateurs pour stocker les donn√©es et les instructions en cours d'utilisation ou de traitement. 
Elle permet un acc√®s rapide √† la lecture et √† l'√©criture, ce qui permet √† l'unit√© centrale (CPU) de r√©cup√©rer rapidement les informations. 
A noter que les donn√©es contenues dans la RAM sont perdues lorsque l'ordinateur est mis hors tension.

##### 3.1.3) Disque dur (SSD, HDD):
**support de stockage non volatil** utilis√© pour stocker les donn√©es, les fichiers et les applications sur un ordinateur. Ils offrent une plus grande capacit√© de stockage que la RAM et conservent les donn√©es m√™me lorsque l'ordinateur est √©teint, ce qui les rend adapt√©s au stockage de donn√©es √† long terme.


>Nb: Il existe aussi un autre type d'espace m√©moire appel√© 'ROM' (Read Only Memory). 
>Il est principalement utilis√©e pour stocker les microprogrammes dont le syst√®me a besoin pour d√©marrer et fonctionner (ex: BIOS/UFI).

Tableau de comparaison: 

| Feature                 | **CPU Cache**                             | **Memory (RAM)**                                        | **Disk Storage**                                             |
| ----------------------- | ----------------------------------------- | ------------------------------------------------------- | ------------------------------------------------------------ |
| **Purpose**                 | Speeds up CPU data access                 | Temporary storage for active data and programs          | Permanent storage for data and files                         |
| **Location**        | Inside the CPU (L1, L2, L3 caches)        | Separate from the CPU, on the motherboard               | On hard drives (HDD) or solid-state drives (SSD)             |
| **Speed**             | Extremely fast (nanoseconds)              | Fast (microseconds)                                     | Slow (milliseconds to seconds)                               |
| **Size**              | Small (typically a few MBs)               | Moderate (a few GBs to hundreds of GBs)                 | Large (hundreds of GBs to several TBs)                       |
| **Volatility**          | Volatile (data lost when power is off)    | Volatile (data lost when power is off)                  | Non-volatile (data retained when power is off)               |
| **Cost**                | Most expensive per GB                     | Moderate cost per GB                                    | Least expensive per GB                                       |
| **Accessibility**       | Frequently accessed data and instructions | Active data for running applications                    | Infrequently accessed data, files, and backups               |
| **Data Management** | Managed by the CPU                        | Managed by the OS and applications                      | Managed by the OS and file systems                           |
| **Hierarchy**          | Has multiple levels (L1, L2, L3)          | No hierarchy, but may have different types (DDR4, DDR5) | Usually one level, but can have different formats (HDD, SSD) |
| **Usage context**    | Accessed during CPU processing cycles     | Used during program execution                           | Used for long-term data storage                              |

Chaque c≈ìur de processeur poss√®de sa propre m√©moire cache (L1 et L2 pour √™tre pr√©cis). Le cache L3 est partag√© entre les diff√©rents c≈ìurs CPU. 

![alt text](img/cours3/cpu-cache.png)

Par CPU:

![alt text](img/cours3/diagram-glossary-caching.svg)

### 3.2) Structure de donn√©es au coeur des BDDs üìå

Les index, les hachages et les arbres sont des structures de donn√©es utilis√©es dans les bases de donn√©es pour optimiser l'acc√®s et la r√©cup√©ration des donn√©es. 

##### 3.2.1) Indexes
Concept et structures de donn√©es permettant d'optimiser la recherche d'enregistrement dans une base de donn√©e. Un index peut √™tre cr√©e via diverses structures de donn√©es, le plus souvent via des tables de hachages ou des B-Trees (cf ce qui suit). 

![alt text](img/cours3/indexes.PNG)

Il est g√©n√©ralement stock√© dans un format cl√©-valeur o√π la cl√© est le champ ou la colonne (tri√©) et la valeur est le(s) pointeur(s).
Ex: John Smith -> 152; Lisa Smith -> 001

Pensez √† l'index d'un livre : au lieu de parcourir chaque page pour trouver une information, on consulte l'index pour aller directement √† la bonne page.
Il est donc plus facile de retrouver une information en parcourant l'index que la table. 

Utilisez des index sur :
1. Les colonnes fr√©quemment utilis√©es dans les clauses WHERE
2. Les colonnes impliqu√©es dans les jointures (cl√©s √©trang√®res)
3. Les colonnes souvent utilis√©es pour le tri (ORDER BY)
4. Les colonnes avec une grande cardinalit√© (nombreuses valeurs uniques)

Nb: Les index peuvent aussi √™tre cr√©e √† partir de plusieurs colonnes, √† la cr√©ation ou apr√®s que la table soit cr√©√©e. 

```sql
CREATE INDEX idx_first_name ON employees (first_name); --single column
CREATE INDEX idx_name ON employees (last_name, first_name); --multiple columns


-- Utilisation implicite de l'index dans une requ√™te 
SELECT * FROM employees WHERE first_name = 'Alice';
```

>Attention: le gain en lecture et pour certaines op√©rations a un co√ªt. 
>- consommation accrue de stockage: il faut bien stocker la table d'index
>- dur√©e lors des op√©rations d'√©criture (create or update): car il faut aussi  mettre √† jour la table d'index
>- complexit√© de management: bien g√©rer le nombre d'index et s'assurer qu'ils r√©pondent bien aux besoins


##### 3.2.2) Hash 
Les fonctions de hachage font correspondre des donn√©es de taille arbitraire √† des valeurs de taille fixe. Les plus connus sont: SHA-256, SHA-251, BLAKE2.
Le hash sera le r√©sultat de l'application de la fonction de hachage sur une entr√©e. 
Cette entr√©e peut √™tre un du texte, une image, toute donn√©e. Elle manipule donc la repr√©sentation binaire de ces divers √©l√©ments. 

![alt text](img/cours3/hash.PNG)

En base de donn√©e, les tables de hachages sont g√©n√©ralement utilis√©es pour cr√©er des indexes.
 
![alt text](img/cours3/hash_table.PNG)

Utilisez ce type d'index id√©alement pour:
- Pour des requ√™tes √† correspondance exacte
- Example: `SELECT * FROM users WHERE id = 1234`


##### 3.2.3) Arbres (Trees)

En informatique les arbres sont des type de donn√©es abstraites assez r√©pandues. Ils repr√©sentent la donn√©e sous une structure arborescente hi√©rarchique avec un ensemble de n≈ìuds connect√©s. Chaque n≈ìud de l'arbre peut √™tre connect√© √† de nombreux enfants (en fonction du type d'arbre), mais doit √™tre connect√© √† un seul parent, √† l'exception du n≈ìud racine ('root' node), qui n'a pas de parent.

En base de donn√©es, un type d'arbre est souvent utilis√©e pour **l'indexation des donn√©es**: B-tree.  Les arbres B sont des structures de donn√©es arborescentes auto-√©quilibr√©es (ie qui √©quilibre automatiquement la r√©partition des n≈ìuds, afin de conserver un √©quilibre √† chaque niveau de l'arbre) qui conservent des **donn√©es tri√©es et permettent des op√©rations d'insertion, de suppression et de recherche efficaces**. 

Illustrations avec des nombres:
![alt text](img/cours3/graph_number.PNG)

Illustration avec des lettres:
![alt text](img/cours3/graph_letter.PNG)

Utilisez ce type d'index quand: 
- vous utilisez des requ√™tes de s√©lection de plage ou de tri
- Exemple: `SELECT * FROM users WHERE age BETWEEN 20 AND 30`

Dans le cas des indexes type B-Tree, l'√©criture est assez co√ªteuse, en effet une insertion ou mise √† jour n√©cessite de recr√©er l'arbre afin de respecter son "√©quilibre". D'autres types d'arbres pour l'indexation existent, on citera notamment: B+ Tree, et LSM-Tree.

A noter que lorsque vous effectuer la commande: "CREATE INDEX" tr√®s souvent le type d'indexe cr√©e est un B-Tree. Mais ce n'est pas tout le temps cas!
Certains SGBD comme PostgreSQL permettent d'avoir une approche hybride en offrant la possibilit√© de cr√©er des index via fonctions de hachage et arbres (B-Trees). B√©n√©ficiant ainsi des avantages de chacune des approches, mais comme on l'a vu cela augmentera la complexit√© de la gestion des index mais aussi le co√ªt des op√©rations d'√©critures. 


# 4. Syst√®mes de stockage de donn√©es üìå

### 4.1) Diff√©rents syst√®mes 
##### Database 
Une **base de donn√©es** est une **collection structur√©e** de donn√©es organis√©es en **tableaux**, **lignes** et **colonnes**. Elle est sp√©cifiquement con√ßue pour **stocker** et **g√©rer** les donn√©es relatives √† des applications ou services.

##### Data Warehouse
Un **data warehouse** (entrep√¥t de donn√©es) est un r√©f√©rentiel centralis√© con√ßu pour **stocker**, **traiter** et **analyser** de grands volumes de **donn√©es structur√©es.** Il regroupe g√©n√©ralement des donn√©es provenant de sources multiples et prend en charge des requ√™tes et des analyses complexes.

![alt text](img/cours3/etl_data_warehouse.PNG)

##### Datamart
Un **data mart** est un **sous-ensemble** d'un **data warehouse**, souvent ax√© sur un **secteur d'activit√© sp√©cifique**, **d√©partement** ou **fonction**. Il est adapt√© aux besoins d'un groupe particulier d'utilisateurs au sein d'une organisation.

##### Datalake
Datalake ou lac de donn√©es en fran√ßais, est un **r√©f√©rentiel centralis√©** qui stocke des donn√©es structur√©es et non structur√©es √† grande √©chelle, **dans leur format natif**.
Il englobe les donn√©es:
- structur√©es, 
- semi-structur√©es (JSON, XML) 
- et non structur√©es (texte, images, vid√©os).

Caract√©ristiques :
- Utilise la logique ELT (Extraction, Chargement, Transformation) plut√¥t que ETL traditionnel. La transformation des donn√©es s'effectuant donc apr√®s l'extraction et le d√©p√¥t sur le data lake. 
- Supporte la virtualisation des donn√©es pour un acc√®s unifi√©.
  La virtualisation des donn√©es cr√©e une couche d'abstraction au-dessus des diff√©rentes sources de donn√©es dans le lac. Cette couche permet d'acc√©der √† toutes les donn√©es comme si elles √©taient dans une seule base de donn√©es unifi√©e, quel que soit leur format ou leur emplacement r√©el. (Ex: Apache Drill, Trino, Denodo, Hive...)
  
  >![alt text](img/cours3/apache_drill.PNG)

- Int√®gre souvent un catalogue de donn√©es pour la gouvernance et la d√©couverte des donn√©es. 
- Utilise des formats de table sp√©cifiques (comme Delta Lake) offrant des fonctionnalit√©s similaires aux bases de donn√©es sur des fichiers distribu√©s.
  
  ![alt text](img/cours3/common_data_lake_tech.PNG)


### 4.2) Comparaison

![alt text](img/cours3/diff_db_dm_dw_dl.PNG)



# 5. Syst√®me de fichiers (File systems) üìå

### Definition: 
Un **syst√®me de fichiers** est une m√©thode et une structure de donn√©es utilis√©es par les syst√®mes d'exploitation pour g√©rer et organiser les fichiers sur les p√©riph√©riques de stockage (tels que les disques durs, les disques SSD, les cl√©s USB, etc.). Il d√©finit la mani√®re dont les donn√©es sont stock√©es, r√©cup√©r√©es et organis√©es, ce qui permet aux utilisateurs et aux applications d'acc√©der aux fichiers et de les manipuler efficacement. En principe, tout syst√®me de fichiers peut stocker n'importe quel format de fichier. Pour le syst√®me de fichiers, tous les fichiers ne sont que des s√©quences d'octets.

Il est compos√© de :
- fichiers
- dossiers ou r√©pertoires
- m√©tadonn√©es de fichiers (type, date, taille, droits etc...)
- chemins d'acc√®s aux fichiers (filepath, ex: C://Users/Documents/MyFolder)

Exemple: Linux file systems
![alt text](img/cours3/linux_fs.jpg)
Il permet aux utilisateurs et aux applications de stocker, d'extraire et de g√©rer efficacement les fichiers. 

Dans le contexte du Big Data, les syst√®mes de fichiers traditionnels ne suffisent plus, car nous sommes dans un paradigme distribu√©. Plusieurs solutions ont √©t√© d√©velopp√©es pour r√©pondre aux besoins sp√©cifiques du stockage et du traitement de grandes quantit√©s de donn√©es.

### Exemples de file systems:
- **HDFS (Hadoop Distributed File System)**:
	- Partie int√©grante de l'√©cosyst√®me Hadoop
	- Caract√©ristiques :
	    - Distribu√© : les donn√©es sont r√©parties sur plusieurs n≈ìuds
	    - Hautement tol√©rant aux pannes : r√©plication des donn√©es
	    - Optimis√© pour les grands fichiers et le streaming de donn√©es

- **DBFS (Databricks File System)**:
	- Syst√®me de fichiers **abstrait** utilis√© dans Databricks. Il permet d'acc√©der √† diff√©rents types de fichiers (.png, .csv, .parquet, .orc etc...), situ√©s √† divers endroits (espace de travail, cache, HDFS, BDD relationnelles/non-relationnelles). Il permet aussi d'impl√©menter des politiques et controles d'acc√®s aux fichiers.
	- Caract√©ristiques :
	    - Compatible HDFS
	    - Int√©gration transparente avec le cloud (AWS S3, Azure Blob Storage, etc.)
	    - Optimis√© pour les workloads Spark
	- Concepts:
		- Mount: un objet qui sert de point d'acc√®s facile √† un syst√®me de stockage externe dans notre environnement Databricks. Lorsque vous cr√©ez un montage (mount), vous dites √† Databricks : ¬´Lorsque je fais r√©f√©rence √† ce chemin dans DBFS, je veux en fait acc√©der √† cet emplacement de stockage externe sp√©cifique¬ª.
		- Root: le r√©pertoire "racine" permettant d'importer des fichiers ou cr√©er des dossiers dans notre espace de travail
		- Ephemeral storage:  Le stockage √©ph√©m√®re est le stockage temporaire disponible sur les machines virtuelles au sein d'un cluster. Les donn√©es √©crites dessus (mis en cache) disparaisse une fois le cluster √©teint ou mis en arr√™t.

- Cloud file systems:
	- ADLS (Azure Data Lake Systems Gen2): 
		```text
		abfs://mycontainer@mystorageaccount.dfs.core.windows.net/folder/file.csv
		```

	- Amazon S3
		```text
		s3a://my-bucket/folder/file.csv
		```

	- Google  Cloud storage
		```text
		gs://my-bucket/folder/file.csv
		```


# 6. Formats üìå
Les formats de fichiers d√©finissent la mani√®re dont les donn√©es sont structur√©es dans un fichier (par exemple, CSV, Parquet, JSON). C'est √† l'application qui lit le fichier de comprendre et d'interpr√©ter son format.

En big data les formats de fichiers jouent un r√¥le crucial dans le stockage, le traitement et l'analyse des donn√©es. Des formats tels que Parquet, ORC et Avro sont con√ßus pour traiter efficacement de grands volumes de donn√©es dans les environnements big data. Il est essentiel de comprendre ces formats pour optimiser les flux de donn√©es, garantir l'int√©grit√© des donn√©es et maximiser la vitesse de traitement.

![alt text](img/cours3/format_choix.PNG)


##### Comparaison des principaux formats: Avro, Orc et Parquet:

| Feature          | Avro                     | ORC                      | Parquet                 |
|------------------|--------------------------|--------------------------|-------------------------|
| Type             | Row-based                | Columnar                 | Columnar                |
| Compression      | Good                     | Excellent                | Excellent               |
| Read Performance | Good                     | Very High                | Very High               |
| Write Performance| Very Good                | Good                     | Moderate                |
| Schema Evolution | Excellent                | Good                     | Good                    |
| Splittable       | Yes                      | Yes                      | Yes                     |
| Language Support | Many languages           | Primarily Java           | Many languages          |
| Key Perk         | Flexible schema evolution| Fast for Hive queries    | Efficient for analytics |
| When to Use      | - Data serialization     | - Hive-based analytics   | - General analytics     |
|                  | - Frequent schema changes| - Fast HDFS integration  | - Data warehousing      |
|                  | - Write-heavy workloads  | - Read-heavy workloads   | - Read-heavy workloads  |
| Best For         | Streaming data, ETL      | Hive queries, HDFS       | General analytics       |
| Ecosystem Fit    | Kafka, Hadoop            | Hadoop, especially Hive  | Spark, general Big Data |

##### Quand choisir quel format ?
- **Avro**: si vous avez besoin d'une √©volution flexible des sch√©mas ou si vous traitez des donn√©es en continu.
- **ORC**: si vous travaillez principalement avec Hive dans un environnement Hadoop.
- **Parquet**: pour l'analyse g√©n√©rale, en particulier si vous utilisez Spark ou si vous avez besoin d'un format qui fonctionne bien avec diff√©rents outils Big Data.


---
Sources:
- https://www.linkedin.com/pulse/differences-between-database-vs-data-warehouse-mart-lake-nguyen-tuan-ejo7c/
- https://www.ssp.sh/blog/data-warehouse-vs-data-lake-etl-vs-elt/
- https://www.ssp.sh/brain/data-lake-file-formats/
- https://blog.bytebytego.com/p/ep63-linux-file-system-explained